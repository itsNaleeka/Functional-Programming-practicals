2024.07.29 16:29:50 INFO  Started: Metals version 1.3.4 in folders 'D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@7192e49]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@da9842b]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@7192e49]
2024.07.29 16:29:52 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
Jul 29, 2024 4:29:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
Jul 29, 2024 4:29:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5
Jul 29, 2024 4:29:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
2024.07.29 16:29:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:29:53 ERROR Unexpected error initializing server: 
java.nio.file.InvalidPathException: Illegal char <"> at index 0: "C:\Program Files\Git\bin\git.exe
	at sun.nio.fs.WindowsPathParser.normalize(WindowsPathParser.java:204)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:175)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77)
	at sun.nio.fs.WindowsPath.parse(WindowsPath.java:92)
	at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:231)
	at java.nio.file.Path.of(Path.java:148)
	at java.nio.file.Paths.get(Paths.java:69)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$4(ScalaCli.scala:350)
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)
	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)
	at scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:600)
	at scala.collection.immutable.Stream$.fromIterator(Stream.scala:469)
	at scala.collection.immutable.Stream$.from(Stream.scala:457)
	at scala.collection.immutable.Stream$.from(Stream.scala:357)
	at scala.collection.IterableFactory$ToFactory.fromSpecific(Factory.scala:274)
	at scala.collection.IterableOnceOps.to(IterableOnce.scala:1437)
	at scala.collection.IterableOnceOps.to$(IterableOnce.scala:1437)
	at scala.collection.AbstractIterator.to(Iterator.scala:1303)
	at scala.collection.IterableOnceOps.toStream(IterableOnce.scala:1482)
	at scala.collection.IterableOnceOps.toStream$(IterableOnce.scala:1482)
	at scala.collection.AbstractIterator.toStream(Iterator.scala:1303)
	at scala.meta.internal.metals.scalacli.ScalaCli$.findInPath$1(ScalaCli.scala:353)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$10(ScalaCli.scala:389)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.scalacli.ScalaCli$.localScalaCli(ScalaCli.scala:391)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli$lzycompute(ScalaCliServers.scala:63)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli(ScalaCliServers.scala:62)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.setupIDE(ScalaCliServers.scala:68)
	at scala.meta.internal.metals.ProjectMetalsLspService.maybeSetupScalaCli(ProjectMetalsLspService.scala:433)
	at scala.meta.internal.metals.ProjectMetalsLspService.$anonfun$onInitialized$1(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.ProjectMetalsLspService.withWillGenerateBspConfig(ProjectMetalsLspService.scala:113)
	at scala.meta.internal.metals.ProjectMetalsLspService.onInitialized(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$initialized$1(MetalsLspService.scala:693)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 16:32:36 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 16:33:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:33:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 29, 2024 4:33:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 39
2024.07.29 16:34:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:34:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:34:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:34:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:34:20 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 16:34:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:35:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:36:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:37:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:37:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:37:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:37:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:37:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:38:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 16:41:24 INFO  Shutting down server
2024.07.29 16:41:24 INFO  shutting down Metals
2024.07.29 16:41:24 INFO  Exiting server
2024.07.29 21:23:52 INFO  Started: Metals version 1.3.4 in folders 'D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@6c6a60d]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@1877b7fb]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@6c6a60d]
2024.07.29 21:23:54 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.29 21:23:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:23:56 ERROR Unexpected error initializing server: 
java.nio.file.InvalidPathException: Illegal char <"> at index 0: "C:\Program Files\Git\bin\git.exe
	at sun.nio.fs.WindowsPathParser.normalize(WindowsPathParser.java:204)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:175)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77)
	at sun.nio.fs.WindowsPath.parse(WindowsPath.java:92)
	at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:231)
	at java.nio.file.Path.of(Path.java:148)
	at java.nio.file.Paths.get(Paths.java:69)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$4(ScalaCli.scala:350)
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)
	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)
	at scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:600)
	at scala.collection.immutable.Stream$.fromIterator(Stream.scala:469)
	at scala.collection.immutable.Stream$.from(Stream.scala:457)
	at scala.collection.immutable.Stream$.from(Stream.scala:357)
	at scala.collection.IterableFactory$ToFactory.fromSpecific(Factory.scala:274)
	at scala.collection.IterableOnceOps.to(IterableOnce.scala:1437)
	at scala.collection.IterableOnceOps.to$(IterableOnce.scala:1437)
	at scala.collection.AbstractIterator.to(Iterator.scala:1303)
	at scala.collection.IterableOnceOps.toStream(IterableOnce.scala:1482)
	at scala.collection.IterableOnceOps.toStream$(IterableOnce.scala:1482)
	at scala.collection.AbstractIterator.toStream(Iterator.scala:1303)
	at scala.meta.internal.metals.scalacli.ScalaCli$.findInPath$1(ScalaCli.scala:353)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$10(ScalaCli.scala:389)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.scalacli.ScalaCli$.localScalaCli(ScalaCli.scala:391)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli$lzycompute(ScalaCliServers.scala:63)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli(ScalaCliServers.scala:62)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.setupIDE(ScalaCliServers.scala:68)
	at scala.meta.internal.metals.ProjectMetalsLspService.maybeSetupScalaCli(ProjectMetalsLspService.scala:433)
	at scala.meta.internal.metals.ProjectMetalsLspService.$anonfun$onInitialized$1(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.ProjectMetalsLspService.withWillGenerateBspConfig(ProjectMetalsLspService.scala:113)
	at scala.meta.internal.metals.ProjectMetalsLspService.onInitialized(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$initialized$1(MetalsLspService.scala:693)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:38:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:52 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:38:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:52 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:38:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:55 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:38:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:55 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:38:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:59 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:38:59 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:38:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:59 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:38:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:38:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:00 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:01 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:03 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:05 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:06 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:06 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:07 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:07 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:07 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:07 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:08 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:09 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:13 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:13 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:13 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:13 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:16 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:16 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:16 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:17 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:18 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:18 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:18 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:24 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:25 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:26 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:26 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:29 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:29 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:29 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:29 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:30 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:31 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:31 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:32 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:32 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:33 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:33 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:34 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:36 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:37 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:38 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:40 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:40 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:42 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:42 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:42 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:43 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:43 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:44 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:44 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:45 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:46 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:47 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:47 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:47 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:47 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:51 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:52 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:52 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:52 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:53 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:56 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:57 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:57 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:58 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:58 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:58 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:39:59 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:39:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:39:59 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:11 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:12 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:12 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:13 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:14 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:14 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:16 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:16 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:17 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:17 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:17 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:18 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:18 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:19 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:19 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:20 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:20 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:20 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:20 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:21 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:21 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:25 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:26 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:27 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:26 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:28 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:28 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:29 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:30 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:30 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:30 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:31 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:31 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:33 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:34 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:33 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:33 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:34 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:34 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:36 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:36 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:40 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:43 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:43 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:44 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:44 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:47 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:47 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:48 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:48 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:49 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:49 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:49 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:50 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:51 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:53 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:53 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:53 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:54 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:55 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:54 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:55 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:56 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:56 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:57 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:58 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:40:58 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:40:59 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:40:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:00 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:01 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
Jul 29, 2024 9:41:01 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 563
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:01 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:02 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:02 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:41:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:02 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:03 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:03 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:41:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:03 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:03 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:04 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:41:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:04 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:05 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:04 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:41:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:15 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:17 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:17 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:18 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:41:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:18 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:18 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:19 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:41:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:19 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:34 WARN  Could not find semantic tokens for: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala
2024.07.29 21:41:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:35 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:41:35 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:41:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:35 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:41:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:47 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:41:49 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:41:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:41:49 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:42:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:22 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:42:23 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:42:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:42:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:42:23 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:42:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:24 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:42:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:25 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 21:42:25 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.29 21:42:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 21:42:25 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 22:24:27 INFO  Shutting down server
2024.07.29 22:24:27 INFO  shutting down Metals
2024.07.29 22:24:27 INFO  Exiting server
2024.07.29 22:46:02 INFO  Started: Metals version 1.3.4 in folders 'D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@96ec020]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@6f490257]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@96ec020]
2024.07.29 22:46:04 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.29 22:46:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 22:46:06 ERROR Unexpected error initializing server: 
java.nio.file.InvalidPathException: Illegal char <"> at index 0: "C:\Program Files\Git\bin\git.exe
	at sun.nio.fs.WindowsPathParser.normalize(WindowsPathParser.java:204)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:175)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77)
	at sun.nio.fs.WindowsPath.parse(WindowsPath.java:92)
	at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:231)
	at java.nio.file.Path.of(Path.java:148)
	at java.nio.file.Paths.get(Paths.java:69)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$4(ScalaCli.scala:350)
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)
	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)
	at scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:600)
	at scala.collection.immutable.Stream$.fromIterator(Stream.scala:469)
	at scala.collection.immutable.Stream$.from(Stream.scala:457)
	at scala.collection.immutable.Stream$.from(Stream.scala:357)
	at scala.collection.IterableFactory$ToFactory.fromSpecific(Factory.scala:274)
	at scala.collection.IterableOnceOps.to(IterableOnce.scala:1437)
	at scala.collection.IterableOnceOps.to$(IterableOnce.scala:1437)
	at scala.collection.AbstractIterator.to(Iterator.scala:1303)
	at scala.collection.IterableOnceOps.toStream(IterableOnce.scala:1482)
	at scala.collection.IterableOnceOps.toStream$(IterableOnce.scala:1482)
	at scala.collection.AbstractIterator.toStream(Iterator.scala:1303)
	at scala.meta.internal.metals.scalacli.ScalaCli$.findInPath$1(ScalaCli.scala:353)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$10(ScalaCli.scala:389)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.scalacli.ScalaCli$.localScalaCli(ScalaCli.scala:391)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli$lzycompute(ScalaCliServers.scala:63)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli(ScalaCliServers.scala:62)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.setupIDE(ScalaCliServers.scala:68)
	at scala.meta.internal.metals.ProjectMetalsLspService.maybeSetupScalaCli(ProjectMetalsLspService.scala:433)
	at scala.meta.internal.metals.ProjectMetalsLspService.$anonfun$onInitialized$1(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.ProjectMetalsLspService.withWillGenerateBspConfig(ProjectMetalsLspService.scala:113)
	at scala.meta.internal.metals.ProjectMetalsLspService.onInitialized(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$initialized$1(MetalsLspService.scala:693)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 22:46:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.29 22:46:55 INFO  Shutting down server
2024.07.29 22:46:55 INFO  shutting down Metals
2024.07.29 22:46:55 INFO  Exiting server
2024.07.30 06:35:46 INFO  Started: Metals version 1.3.4 in folders 'D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@1877b7fb]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@3e1ef0c0]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@1877b7fb]
2024.07.30 06:35:49 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.30 06:35:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:35:50 ERROR Unexpected error initializing server: 
java.nio.file.InvalidPathException: Illegal char <"> at index 0: "C:\Program Files\Git\bin\git.exe
	at sun.nio.fs.WindowsPathParser.normalize(WindowsPathParser.java:204)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:175)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77)
	at sun.nio.fs.WindowsPath.parse(WindowsPath.java:92)
	at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:231)
	at java.nio.file.Path.of(Path.java:148)
	at java.nio.file.Paths.get(Paths.java:69)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$4(ScalaCli.scala:350)
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)
	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)
	at scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:600)
	at scala.collection.immutable.Stream$.fromIterator(Stream.scala:469)
	at scala.collection.immutable.Stream$.from(Stream.scala:457)
	at scala.collection.immutable.Stream$.from(Stream.scala:357)
	at scala.collection.IterableFactory$ToFactory.fromSpecific(Factory.scala:274)
	at scala.collection.IterableOnceOps.to(IterableOnce.scala:1437)
	at scala.collection.IterableOnceOps.to$(IterableOnce.scala:1437)
	at scala.collection.AbstractIterator.to(Iterator.scala:1303)
	at scala.collection.IterableOnceOps.toStream(IterableOnce.scala:1482)
	at scala.collection.IterableOnceOps.toStream$(IterableOnce.scala:1482)
	at scala.collection.AbstractIterator.toStream(Iterator.scala:1303)
	at scala.meta.internal.metals.scalacli.ScalaCli$.findInPath$1(ScalaCli.scala:353)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$10(ScalaCli.scala:389)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.scalacli.ScalaCli$.localScalaCli(ScalaCli.scala:391)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli$lzycompute(ScalaCliServers.scala:63)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli(ScalaCliServers.scala:62)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.setupIDE(ScalaCliServers.scala:68)
	at scala.meta.internal.metals.ProjectMetalsLspService.maybeSetupScalaCli(ProjectMetalsLspService.scala:433)
	at scala.meta.internal.metals.ProjectMetalsLspService.$anonfun$onInitialized$1(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.ProjectMetalsLspService.withWillGenerateBspConfig(ProjectMetalsLspService.scala:113)
	at scala.meta.internal.metals.ProjectMetalsLspService.onInitialized(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$initialized$1(MetalsLspService.scala:693)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:35:54 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:37:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:37:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:04 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:38:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:04 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[IDInt, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:38:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:05 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:38:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:05 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[ID:Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:38:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:10 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:38:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[ID:Int, Name:String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:38:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:12 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[ID:Int, Name:String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:38:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 30, 2024 6:38:26 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 52
2024.07.30 06:38:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 30, 2024 6:38:28 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: An unexpected exception occurred while executing jsonrpc method public abstract java.util.concurrent.CompletableFuture scala.meta.metals.lsp.TextDocumentService.definition(org.eclipse.lsp4j.TextDocumentPositionParams)
java.lang.IllegalStateException: An unexpected exception occurred while executing jsonrpc method public abstract java.util.concurrent.CompletableFuture scala.meta.metals.lsp.TextDocumentService.definition(org.eclipse.lsp4j.TextDocumentPositionParams)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$recursiveFindRpcMethods$0(GenericEndpoint.java:73)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.request(GenericEndpoint.java:128)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleRequest(RemoteEndpoint.java:271)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:201)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:185)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:97)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:114)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
Caused by: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[ID:Int, Name:String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.mtags.ScalaToplevelMtags$XtensionScanner.mtagsNextToken(ScalaToplevelMtags.scala:67)
	at scala.meta.internal.mtags.ScalaToplevelMtags.acceptBalancedDelimeters(ScalaToplevelMtags.scala:866)
	at scala.meta.internal.mtags.ScalaToplevelMtags.loop(ScalaToplevelMtags.scala:494)
	at scala.meta.internal.mtags.ScalaToplevelMtags.indexRoot(ScalaToplevelMtags.scala:79)
	at scala.meta.internal.mtags.MtagsIndexer.index(MtagsIndexer.scala:21)
	at scala.meta.internal.mtags.MtagsIndexer.index$(MtagsIndexer.scala:20)
	at scala.meta.internal.mtags.ScalaToplevelMtags.index(ScalaToplevelMtags.scala:43)
	at scala.meta.internal.mtags.Mtags$.allToplevels(Mtags.scala:154)
	at scala.meta.internal.metals.DefinitionProvider.fromMtags(DefinitionProvider.scala:405)
	at scala.meta.internal.metals.DefinitionProvider.$anonfun$positionOccurrence$4(DefinitionProvider.scala:324)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.DefinitionProvider.$anonfun$positionOccurrence$1(DefinitionProvider.scala:324)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.DefinitionProvider.positionOccurrence(DefinitionProvider.scala:316)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$definitionOrReferences$1(MetalsLspService.scala:1644)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.MetalsLspService.definitionOrReferences(MetalsLspService.scala:1640)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$definition$1(MetalsLspService.scala:978)
	at scala.meta.internal.metals.CancelTokens$.future(CancelTokens.scala:38)
	at scala.meta.internal.metals.MetalsLspService.definition(MetalsLspService.scala:977)
	at scala.meta.internal.metals.WorkspaceLspService.definition(WorkspaceLspService.scala:423)
	at scala.meta.metals.lsp.DelegatingScalaService.definition(DelegatingScalaService.scala:69)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$recursiveFindRpcMethods$0(GenericEndpoint.java:65)
	... 11 more

2024.07.30 06:38:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:29 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:38:30 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:38:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:38:30 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:42:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:05 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:05 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:45:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:05 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:07 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:07 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:07 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:08 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:45:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:09 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:09 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:45:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:09 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:10 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:45:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:12 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:45:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:12 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:38 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:45:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:45:44 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:12 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:15 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:16 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:16 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:16 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:17 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:18 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:18 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:19 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:19 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:20 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:20 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:20 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:20 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:21 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:22 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:22 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:22 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:24 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:24 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:26 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:28 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:29 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:30 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:31 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:44 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:45 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:45 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:46 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:46 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:47 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:47 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:47 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:47 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:51 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:46:52 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:46:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:46:52 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:12 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:12 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:47:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:12 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:18 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:19 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:47:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:19 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:19 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:21 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:21 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:47:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:21 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:24 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:25 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:28 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:29 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:29 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:30 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:33 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:34 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:35 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:35 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:36 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:37 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:47:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:37 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:37 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:37 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:47:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:37 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:39 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:39 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:47:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:39 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:39 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:40 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:47:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:40 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:47:43 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:47:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:47:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:52:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, ] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Do] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Doub] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:13 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:52:14 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:52:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:52:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:31 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String,] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 06:52:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:32 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 06:52:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 06:52:32 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String,] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:15 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:15 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, ] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Do] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Doub] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:18 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:18 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:01:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:18 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple", 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 30, 2024 7:01:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 605
2024.07.30 07:01:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:40 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" , 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:41 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0., 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:42 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:01:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0., 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:43 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:01:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana", 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:48 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:48 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" , 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:49 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7, 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:50 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:01:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:50 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7, 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:49 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7., 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:51 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.8, 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:51 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:52 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:01:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:52 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango");
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:55 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" );
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:55 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:55 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:56 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.5);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:57 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:01:57 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:01:56 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:57 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:01:57 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:02:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\practical05_1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:02:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\practical05_1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:03:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\practical05_1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:03:22 INFO  no build target found for d:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\practical05_1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:03:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:03:22 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:03:58 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.30 07:03:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-05\practical05_2.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:03:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-05\practical05_2.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 30, 2024 7:04:00 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 731
2024.07.30 07:04:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-05\practical05_2.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:05 INFO  time: code lens generation in 5.76s
2024.07.30 07:04:05 INFO  time: code lens generation in 5.52s
2024.07.30 07:04:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-05\practical05_2.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-05\practical05_2.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-05\practical05_2.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-05\practical05_2.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 30, 2024 7:04:14 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 745
2024.07.30 07:04:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:35 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:35 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:04:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:35 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:38 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:43 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:04:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:46 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:04:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:46 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:46 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:04:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:46 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:49 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:49 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:04:50 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:04:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:04:50 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:19 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:19 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:19 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:21 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:21 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:21 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:22 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:22 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:23 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:24 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:25 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:25 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:28 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:28 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:29 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:29 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:29 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:30 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:30 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:30 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:32 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:32 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:33 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:33 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:34 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:33 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:35 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:35 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:38 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:38 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:39 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:39 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:41 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:41 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:40 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:42 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:44 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:45 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:45 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:45 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:45 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:05:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:45 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:45 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:50 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:50 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:50 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:53 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:53 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:05:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:05:58 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:02 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:03 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:03 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:04 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:04 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:05 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:05 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:05 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:08 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:11 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:13 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:13 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:13 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:14 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:16 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:17 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:18 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:18 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:18 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:31 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:32 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:33 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:33 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:33 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:35 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:36 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:36 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:36 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:37 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:37 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:38 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:38 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:37 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:37 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:41 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:41 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:41 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:41 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:43 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:44 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:44 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:45 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:45 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:45 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:51 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:52 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:52 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:52 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:52 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:54 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:54 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:55 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:55 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:55 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:58 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:58 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:06:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:58 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:59 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:06:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:00 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:06:59 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:00 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:01 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:01 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:01 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:02 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:02 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:02 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:01 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:03 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:09 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:09 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:11 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:12 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:13 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:13 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:19 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:19 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:19 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:19 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:23 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:23 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:22 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:24 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:24 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:24 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:25 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:24 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:25 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:25 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:26 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:26 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:27 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:26 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:27 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:27 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:28 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:28 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:28 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:30 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:30 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:31 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:07:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:31 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:31 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:07:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:07:58 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 30, 2024 7:08:00 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1439
2024.07.30 07:08:00 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:02 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:04 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:05 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:08:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:05 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:05 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:06 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:06 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:08:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:06 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:06 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:10 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:10 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:11 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:08:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:11 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:11 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:12 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:12 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:13 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:13 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:14 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:08:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:14 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String, Double] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:14 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:16 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String,] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:16 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:16 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:17 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:08:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:17 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 30, 2024 7:08:30 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1546
2024.07.30 07:08:29 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
Jul 30, 2024 7:08:31 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: An unexpected exception occurred while executing jsonrpc method public abstract java.util.concurrent.CompletableFuture scala.meta.metals.lsp.TextDocumentService.definition(org.eclipse.lsp4j.TextDocumentPositionParams)
java.lang.IllegalStateException: An unexpected exception occurred while executing jsonrpc method public abstract java.util.concurrent.CompletableFuture scala.meta.metals.lsp.TextDocumentService.definition(org.eclipse.lsp4j.TextDocumentPositionParams)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$recursiveFindRpcMethods$0(GenericEndpoint.java:73)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.request(GenericEndpoint.java:128)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleRequest(RemoteEndpoint.java:271)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:201)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:185)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:97)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:114)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
Caused by: file:///D:/2nd%20year/Functional%20Programming/Functional-Programming-practicals/practicals-06/1.scala:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" 0.50, 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.mtags.ScalaToplevelMtags$XtensionScanner.mtagsNextToken(ScalaToplevelMtags.scala:67)
	at scala.meta.internal.mtags.ScalaToplevelMtags.acceptBalancedDelimeters(ScalaToplevelMtags.scala:866)
	at scala.meta.internal.mtags.ScalaToplevelMtags.loop(ScalaToplevelMtags.scala:494)
	at scala.meta.internal.mtags.ScalaToplevelMtags.indexRoot(ScalaToplevelMtags.scala:79)
	at scala.meta.internal.mtags.MtagsIndexer.index(MtagsIndexer.scala:21)
	at scala.meta.internal.mtags.MtagsIndexer.index$(MtagsIndexer.scala:20)
	at scala.meta.internal.mtags.ScalaToplevelMtags.index(ScalaToplevelMtags.scala:43)
	at scala.meta.internal.mtags.Mtags$.allToplevels(Mtags.scala:154)
	at scala.meta.internal.metals.DefinitionProvider.fromMtags(DefinitionProvider.scala:405)
	at scala.meta.internal.metals.DefinitionProvider.$anonfun$positionOccurrence$4(DefinitionProvider.scala:324)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.DefinitionProvider.$anonfun$positionOccurrence$1(DefinitionProvider.scala:324)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.DefinitionProvider.positionOccurrence(DefinitionProvider.scala:316)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$definitionOrReferences$1(MetalsLspService.scala:1644)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.MetalsLspService.definitionOrReferences(MetalsLspService.scala:1640)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$definition$1(MetalsLspService.scala:978)
	at scala.meta.internal.metals.CancelTokens$.future(CancelTokens.scala:38)
	at scala.meta.internal.metals.MetalsLspService.definition(MetalsLspService.scala:977)
	at scala.meta.internal.metals.WorkspaceLspService.definition(WorkspaceLspService.scala:423)
	at scala.meta.metals.lsp.DelegatingScalaService.definition(DelegatingScalaService.scala:69)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$recursiveFindRpcMethods$0(GenericEndpoint.java:65)
	... 11 more

2024.07.30 07:08:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:33 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" , 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:33 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:08:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:33 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:33 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" , 002 -> "Banana" 7.80, 003 -> "Mango" 4.50);
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:36 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:39 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:41 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" , 002 -> "Banana" , 003 -> "Mango" 4.50);
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" , 002 -> "Banana", 003 -> "Mango" 4.50);
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:41 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:42 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:08:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:42 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" , 002 -> "Banana", 003 -> "Mango" 4.50);
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:42 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:43 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:45 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:46 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" , 002 -> "Banana", 003 -> "Mango" );
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:08:46 WARN  no build target for: D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
2024.07.30 07:08:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:46 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 07:08:46 ERROR Failed to tokenize input for semantic tokens for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\1.scala
scala.meta.tokenizers.TokenizeException: <input>:2: error: Non-zero integral values may not have a leading zero.
  val Inventory1: Map[Int, String] = Map(001 -> "Apple" , 002 -> "Banana", 003 -> "Mango" );
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInt$1(LegacyScanner.scala:786)
	at scala.meta.internal.tokenizers.LegacyScanner.setNumberInteger$1(LegacyScanner.scala:797)
	at scala.meta.internal.tokenizers.LegacyScanner.getNumber(LegacyScanner.scala:811)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchZero$1(LegacyScanner.scala:320)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:323)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 07:19:46 INFO  Shutting down server
2024.07.30 07:19:46 INFO  shutting down Metals
2024.07.30 07:19:46 INFO  Exiting server
2024.07.30 09:30:56 INFO  Started: Metals version 1.3.4 in folders 'D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@517070ed]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@12d3ee1]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@517070ed]
2024.07.30 09:30:56 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.30 09:30:59 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\practical06_1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 09:30:59 ERROR Unexpected error initializing server: 
java.nio.file.InvalidPathException: Illegal char <"> at index 0: "C:\Program Files\Git\bin\git.exe
	at sun.nio.fs.WindowsPathParser.normalize(WindowsPathParser.java:204)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:175)
	at sun.nio.fs.WindowsPathParser.parse(WindowsPathParser.java:77)
	at sun.nio.fs.WindowsPath.parse(WindowsPath.java:92)
	at sun.nio.fs.WindowsFileSystem.getPath(WindowsFileSystem.java:231)
	at java.nio.file.Path.of(Path.java:148)
	at java.nio.file.Paths.get(Paths.java:69)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$4(ScalaCli.scala:350)
	at scala.collection.Iterator$$anon$9.next(Iterator.scala:584)
	at scala.collection.Iterator$$anon$6.hasNext(Iterator.scala:478)
	at scala.collection.Iterator$$anon$9.hasNext(Iterator.scala:583)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:600)
	at scala.collection.immutable.Stream$.fromIterator(Stream.scala:469)
	at scala.collection.immutable.Stream$.from(Stream.scala:457)
	at scala.collection.immutable.Stream$.from(Stream.scala:357)
	at scala.collection.IterableFactory$ToFactory.fromSpecific(Factory.scala:274)
	at scala.collection.IterableOnceOps.to(IterableOnce.scala:1437)
	at scala.collection.IterableOnceOps.to$(IterableOnce.scala:1437)
	at scala.collection.AbstractIterator.to(Iterator.scala:1303)
	at scala.collection.IterableOnceOps.toStream(IterableOnce.scala:1482)
	at scala.collection.IterableOnceOps.toStream$(IterableOnce.scala:1482)
	at scala.collection.AbstractIterator.toStream(Iterator.scala:1303)
	at scala.meta.internal.metals.scalacli.ScalaCli$.findInPath$1(ScalaCli.scala:353)
	at scala.meta.internal.metals.scalacli.ScalaCli$.$anonfun$localScalaCli$10(ScalaCli.scala:389)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.scalacli.ScalaCli$.localScalaCli(ScalaCli.scala:391)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli$lzycompute(ScalaCliServers.scala:63)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.localScalaCli(ScalaCliServers.scala:62)
	at scala.meta.internal.metals.scalacli.ScalaCliServers.setupIDE(ScalaCliServers.scala:68)
	at scala.meta.internal.metals.ProjectMetalsLspService.maybeSetupScalaCli(ProjectMetalsLspService.scala:433)
	at scala.meta.internal.metals.ProjectMetalsLspService.$anonfun$onInitialized$1(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.ProjectMetalsLspService.withWillGenerateBspConfig(ProjectMetalsLspService.scala:113)
	at scala.meta.internal.metals.ProjectMetalsLspService.onInitialized(ProjectMetalsLspService.scala:504)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$initialized$1(MetalsLspService.scala:693)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1570)

2024.07.30 09:31:17 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\practical06_1.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.30 09:31:20 INFO  no build target found for D:\2nd year\Functional Programming\Functional-Programming-practicals\practicals-06\practical06_1.scala. Using presentation compiler with project's scala-library version: 3.3.3
